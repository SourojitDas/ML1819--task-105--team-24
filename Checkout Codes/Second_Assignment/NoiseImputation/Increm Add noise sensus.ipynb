{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "path = '../NumericDataSet/adult.csv'\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "# remove rows where occupation is unknown\n",
    "data = data[data.occupation != '?']\n",
    "raw_data = data[data.occupation != '?']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved New File As ../Census/clean_adult.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>...</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "      <th>workclass_num</th>\n",
       "      <th>marital_num</th>\n",
       "      <th>race_num</th>\n",
       "      <th>sex_num</th>\n",
       "      <th>rel_num</th>\n",
       "      <th>over50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>Private</td>\n",
       "      <td>132870</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>4356</td>\n",
       "      <td>18</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>Private</td>\n",
       "      <td>140359</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>264663</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34</td>\n",
       "      <td>Private</td>\n",
       "      <td>216864</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>3770</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>150601</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>3770</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age workclass  fnlwgt     education  education.num marital.status  \\\n",
       "1   82   Private  132870       HS-grad              9        Widowed   \n",
       "3   54   Private  140359       7th-8th              4       Divorced   \n",
       "4   41   Private  264663  Some-college             10      Separated   \n",
       "5   34   Private  216864       HS-grad              9       Divorced   \n",
       "6   38   Private  150601          10th              6      Separated   \n",
       "\n",
       "          occupation   relationship   race     sex   ...     capital.loss  \\\n",
       "1    Exec-managerial  Not-in-family  White  Female   ...             4356   \n",
       "3  Machine-op-inspct      Unmarried  White  Female   ...             3900   \n",
       "4     Prof-specialty      Own-child  White  Female   ...             3900   \n",
       "5      Other-service      Unmarried  White  Female   ...             3770   \n",
       "6       Adm-clerical      Unmarried  White    Male   ...             3770   \n",
       "\n",
       "   hours.per.week  native.country income workclass_num  marital_num  race_num  \\\n",
       "1              18   United-States  <=50K             0            0         0   \n",
       "3              40   United-States  <=50K             0            1         0   \n",
       "4              40   United-States  <=50K             0            2         0   \n",
       "5              45   United-States  <=50K             0            1         0   \n",
       "6              40   United-States  <=50K             0            2         0   \n",
       "\n",
       "   sex_num  rel_num  over50K  \n",
       "1        0        0        0  \n",
       "3        0        0        0  \n",
       "4        0        0        0  \n",
       "5        0        0        0  \n",
       "6        1        0        0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['workclass_num'] = data.workclass.map({'Private':0, 'State-gov':1, 'Federal-gov':2, 'Self-emp-not-inc':3, 'Self-emp-inc':4, 'Local-gov':5, 'Without-pay':6})\n",
    "data['marital_num'] = data['marital.status'].map({'Widowed':0, 'Divorced':1, 'Separated':2, 'Never-married':3, 'Married-civ-spouse':4, 'Married-AF-spouse':4, 'Married-spouse-absent':5})\n",
    "data['race_num'] = data.race.map({'White':0, 'Black':1, 'Asian-Pac-Islander':2, 'Amer-Indian-Eskimo':3, 'Other':4})\n",
    "data['sex_num'] = np.where(data.sex == 'Female', 0, 1)\n",
    "data['rel_num'] = data.relationship.map({'Not-in-family':0, 'Unmarried':0, 'Own-child':0, 'Other-relative':0, 'Husband':1, 'Wife':1})\n",
    "data['over50K'] = np.where(data.income == '<=50K', 0, 1)\n",
    "\n",
    "\n",
    "\n",
    "#columns = ['workclass', 'marital.status', 'race','sex','relationship','income']\n",
    "#data.drop(columns, inplace=True, axis=1)\n",
    "\n",
    "df1 = pd.DataFrame(data)\n",
    "df1.to_csv(\"../NumericDataSet/clean_adult.csv\")\n",
    "print(\"Saved New File As ../Census/clean_adult.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data....\n",
      "Using clean_adult.csv\n",
      "Adding 10% Noise\n",
      "(30718, 8)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Saved New File As ../NumericDataSet/10_noisy_clean_adult.csv\n",
      "Adding 20% Noise\n",
      "(30718, 8)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "def getNoiseData(dataSet,percent):\n",
    "    #dataSet = np.delete(dataSet,(0), axis=0)\n",
    "    size = dataSet.shape\n",
    "    rows = size[0]\n",
    "    #print(rows)\n",
    "    cols = size[1]\n",
    "   \n",
    "    num = (int)(rows*(percent/100))\n",
    "    end = np.amax(dataSet,axis=0)\n",
    "    start = np.amin(dataSet,axis=0)\n",
    "    #print( start )\n",
    "    #print( end )\n",
    "    \n",
    "    #print(start)\n",
    "    #print(end)\n",
    "    i = 0;\n",
    "    random_val = []\n",
    "    while i<cols:\n",
    "        #print(start[i]+\" \"+end[i])\n",
    "        random_val.append(Rand(start[i],end[i], num))\n",
    "        #print(start[i])\n",
    "        #print(end[i])\n",
    "        i = i+1\n",
    "    return random_val\n",
    "#print(random_rows)\n",
    "\n",
    "\n",
    "def Rand(start, end, num): \n",
    "    res = [] \n",
    "  \n",
    "    for j in range(num): \n",
    "        res.append(random.randint(start, end)) \n",
    "  \n",
    "    return res\n",
    "  \n",
    "def getNoisePlaces(dataSet,percent):\n",
    "    size = dataSet.shape\n",
    "    rows = size[0]\n",
    "    num = (int)(rows*(percent/100))\n",
    "    start = 0\n",
    "    end = rows-1\n",
    "    random_rows=Rand(start, end, num)\n",
    "    return random_rows\n",
    "\n",
    "def readData():\n",
    "    #read both csv files to np array\n",
    "    print(\"Reading Data....\")\n",
    "\n",
    "    #files = os.listdir(\"../NumericData/\")\n",
    "    files = ['clean_adult.csv']\n",
    "    for key in range(0, len(files)):\n",
    "        orginal_dataset = pd.read_csv(\"../NumericDataSet/\"+files[key])\n",
    "        size = orginal_dataset.shape\n",
    "        rows = size[0]\n",
    "        cols = size[1]\n",
    "        \n",
    "        #orginal_dataset = orginal_dataset[:int(rows/7)]\n",
    "        \n",
    "        #df1 = pd.DataFrame(orginal_dataset)\n",
    "        #df1.to_csv(\"../NumericData/clean_\"+files[key])\n",
    "        #print(\"Saved New File As ../NumericData/clean_\"+files[key])\n",
    "        \n",
    "        print(\"Using \"+files[key])\n",
    "    \n",
    "        copy_dataset=orginal_dataset[['workclass_num', 'education.num', 'marital_num', 'race_num', 'sex_num', 'rel_num', 'capital.gain', 'capital.loss']]\n",
    "        other_dataset=orginal_dataset[['workclass','fnlwgt','education','marital.status','occupation','relationship','race','sex','hours.per.week','native.country','income','age','over50K']]\n",
    "                \n",
    "        percent = [10,20,30,40,50]\n",
    "        for x in percent:\n",
    "            print(\"Adding \"+str(x)+\"% Noise\")\n",
    "            random_data = getNoiseData(copy_dataset,x)\n",
    "            \n",
    "            copy_dataset = copy_dataset.reindex(['workclass_num', 'education.num', 'marital_num', 'race_num', 'sex_num', 'rel_num', 'capital.gain', 'capital.loss'], axis=1)\n",
    "            other_dataset = other_dataset.reindex(['workclass','fnlwgt','education','marital.status','occupation','relationship','race','sex','hours.per.week','native.country','income','age','over50K'], axis=1)\n",
    "        \n",
    "            size = copy_dataset.shape\n",
    "            rows = size[0]\n",
    "            cols = size[1]\n",
    "        \n",
    "            print(size)\n",
    "            k = 0\n",
    "            while k<cols:\n",
    "                random_places = getNoisePlaces(copy_dataset,x)\n",
    "                #print(len(random_places))\n",
    "                j = 0\n",
    "                print(k)\n",
    "                while j<len(random_places):\n",
    "                    a = random_data[k][j]\n",
    "                    row2change = random_places[j]\n",
    "                    #print(row2change)\n",
    "                    copy_dataset.iloc[row2change,k] = a\n",
    "                    \n",
    "                    #copy_dataset.itemset((j,k),a)\n",
    "                    \n",
    "                    #print(copy_dataset[j,k])\n",
    "                    #print(random_data[k][j])\n",
    "                    j = j+1\n",
    "                k = k+1\n",
    "            #our_dataset = copy_dataset.append(other_dataset, ignore_index=True)\n",
    "            our_dataset = pd.concat([copy_dataset,other_dataset], axis=1)\n",
    "            #df = pd.DataFrame(our_dataset)\n",
    "            our_dataset.to_csv(\"../NumericDataSet/\"+str(x)+\"_noisy_\"+files[key],index=False)\n",
    "            print(\"Saved New File As ../NumericDataSet/\"+str(x)+\"_noisy_\"+files[key])\n",
    "    print(\"Noise Addition Completed\")\n",
    "\n",
    "\n",
    "readData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
