{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n",
      "(768, 1)\n"
     ]
    }
   ],
   "source": [
    "# Python code to generate \n",
    "# random numbers and \n",
    "# append them to a list \n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "  \n",
    "# Function to generate \n",
    "# and append them  \n",
    "# start = starting range, \n",
    "# end = ending range \n",
    "# num = number of  \n",
    "# elements needs to be appended \n",
    "def Rand(start, end, num): \n",
    "    res = [] \n",
    "  \n",
    "    for j in range(num): \n",
    "        res.append(random.randint(start, end)) \n",
    "  \n",
    "    return res \n",
    "  \n",
    "# Driver Code \n",
    "num = 192\n",
    "start = 0\n",
    "end = 768\n",
    "random_rows=Rand(start, end, num)\n",
    "#print(random_rows)\n",
    "\n",
    "#read both csv files to np array\n",
    "\n",
    "orginal_dataset = pd.read_csv('C:/Users/souro/Desktop/MachineLearningProject/Datasets/pima-indians-diabetes-database/diabetes.csv')\n",
    "noise_dataset =  pd.read_csv('C:/Users/souro/Desktop/MachineLearningProject/Datasets/pima-indians-diabetes-database/noiseDiabetes_STD_2.csv')\n",
    "copy_dataset=orginal_dataset\n",
    "\n",
    "new_noise_data = noise_dataset.iloc[:,0:8]\n",
    "prediction = orginal_dataset.iloc[:,8:]\n",
    "new_noise_data = np.append(new_noise_data,prediction,axis=1)\n",
    "print(new_noise_data.shape)\n",
    "print(prediction.shape)\n",
    "#print(noise_dataset)\n",
    "\n",
    "#replace data in np array\n",
    "\n",
    "for pos in random_rows:\n",
    "    #print(pos)\n",
    "    currdata = new_noise_data[pos:pos+1,:]\n",
    "    positivedata=np.absolute(currdata)\n",
    "    #print(currdata)\n",
    "    copy_dataset[pos:pos+1] = positivedata\n",
    "    \n",
    "copy_dataset=np.absolute(copy_dataset)\n",
    "#print(copy_dataset.shape)\n",
    "#copy_dataset = copy_dataset.iloc[:,1:]\n",
    "#print(copy_dataset.shape)\n",
    "df = pd.DataFrame(copy_dataset)\n",
    "df.to_csv(\"C:/Users/souro/Desktop/MachineLearningProject/Datasets/pima-indians-diabetes-database/pima_indian_25_per.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
